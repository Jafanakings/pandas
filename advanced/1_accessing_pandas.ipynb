{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bb49c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im\n"
     ]
    }
   ],
   "source": [
    "print('im')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ee3a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Downloading numpy-2.3.0-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.0-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 3.4 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.1 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.7/11.1 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.7/11.1 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.1 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.7/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading numpy-2.3.0-cp311-cp311-win_amd64.whl (13.0 MB)\n",
      "   ---------------------------------------- 0.0/13.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/13.0 MB 4.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/13.0 MB 4.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/13.0 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/13.0 MB 4.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/13.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/13.0 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.1/13.0 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.1/13.0 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 8.9/13.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.4/13.0 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.0/13.0 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.2/13.0 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.7/13.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/13.0 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/13.0 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.6/13.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.8/13.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.0/13.0 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------------------------------------- 0/4 [pytz]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   ---------- ----------------------------- 1/4 [tzdata]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   -------------------- ------------------- 2/4 [numpy]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ------------------------------ --------- 3/4 [pandas]\n",
      "   ---------------------------------------- 4/4 [pandas]\n",
      "\n",
      "Successfully installed numpy-2.3.0 pandas-2.3.0 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41441bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1874a1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.58.4-cp311-cp311-win_amd64.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from matplotlib) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.3-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.1 MB 3.4 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.6/8.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.1/8.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.4/8.1 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 3.9/8.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 4.7/8.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.0/8.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 6.3/8.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.2-cp311-cp311-win_amd64.whl (222 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.58.4-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.2 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp311-cp311-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.2.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.8/2.7 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ---------------------------------------- 0/7 [pyparsing]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----- ---------------------------------- 1/7 [pillow]\n",
      "   ----------- ---------------------------- 2/7 [kiwisolver]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ----------------- ---------------------- 3/7 [fonttools]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------- ----------- 5/7 [contourpy]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------- ----- 6/7 [matplotlib]\n",
      "   ---------------------------------------- 7/7 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.58.4 kiwisolver-1.4.8 matplotlib-3.10.3 pillow-11.2.1 pyparsing-3.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e2619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from datasets)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from datasets) (24.2)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.13-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Downloading certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\envs\\python_course\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading aiohttp-3.12.13-cp311-cp311-win_amd64.whl (451 kB)\n",
      "Downloading multidict-6.4.4-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Downloading pyarrow-20.0.0-cp311-cp311-win_amd64.whl (25.8 MB)\n",
      "   ---------------------------------------- 0.0/25.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/25.8 MB 10.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.1/25.8 MB 5.3 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 3.1/25.8 MB 4.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.9/25.8 MB 4.3 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.9/25.8 MB 4.3 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.5/25.8 MB 4.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.6/25.8 MB 4.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 7.3/25.8 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 8.1/25.8 MB 4.1 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.9/25.8 MB 4.0 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.7/25.8 MB 4.0 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.5/25.8 MB 4.0 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 11.5/25.8 MB 3.9 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.6/25.8 MB 3.9 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 13.4/25.8 MB 3.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 14.2/25.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.9/25.8 MB 3.9 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.2/25.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 15.5/25.8 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.3/25.8 MB 3.6 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 17.0/25.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 18.1/25.8 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.9/25.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.9/25.8 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.7/25.8 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.8/25.8 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 22.5/25.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.6/25.8 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.6/25.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.4/25.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.7/25.8 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.8/25.8 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp311-cp311-win_amd64.whl (105 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading xxhash-3.5.0-cp311-cp311-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, urllib3, tqdm, pyyaml, pyarrow, propcache, multidict, idna, fsspec, frozenlist, filelock, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   - --------------------------------------  1/23 [urllib3]\n",
      "   --- ------------------------------------  2/23 [tqdm]\n",
      "   --- ------------------------------------  2/23 [tqdm]\n",
      "   --- ------------------------------------  2/23 [tqdm]\n",
      "   --- ------------------------------------  2/23 [tqdm]\n",
      "   ----- ----------------------------------  3/23 [pyyaml]\n",
      "   ----- ----------------------------------  3/23 [pyyaml]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   ------ ---------------------------------  4/23 [pyarrow]\n",
      "   -------- -------------------------------  5/23 [propcache]\n",
      "   ------------ ---------------------------  7/23 [idna]\n",
      "   ------------ ---------------------------  7/23 [idna]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   ------------- --------------------------  8/23 [fsspec]\n",
      "   --------------- ------------------------  9/23 [frozenlist]\n",
      "   ----------------- ---------------------- 10/23 [filelock]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   ------------------- -------------------- 11/23 [dill]\n",
      "   -------------------- ------------------- 12/23 [charset_normalizer]\n",
      "   -------------------- ------------------- 12/23 [charset_normalizer]\n",
      "   ---------------------- ----------------- 13/23 [certifi]\n",
      "   ------------------------ --------------- 14/23 [attrs]\n",
      "   ------------------------ --------------- 14/23 [attrs]\n",
      "   ------------------------ --------------- 14/23 [attrs]\n",
      "   ------------------------ --------------- 14/23 [attrs]\n",
      "   --------------------------- ------------ 16/23 [yarl]\n",
      "   --------------------------- ------------ 16/23 [yarl]\n",
      "   ----------------------------- ---------- 17/23 [requests]\n",
      "   ----------------------------- ---------- 17/23 [requests]\n",
      "   ----------------------------- ---------- 17/23 [requests]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   ------------------------------- -------- 18/23 [multiprocess]\n",
      "   --------------------------------- ------ 19/23 [aiosignal]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ---------------------------------- ----- 20/23 [huggingface-hub]\n",
      "   ------------------------------------ --- 21/23 [aiohttp]\n",
      "   ------------------------------------ --- 21/23 [aiohttp]\n",
      "   ------------------------------------ --- 21/23 [aiohttp]\n",
      "   ------------------------------------ --- 21/23 [aiohttp]\n",
      "   ------------------------------------ --- 21/23 [aiohttp]\n",
      "   ------------------------------------ --- 21/23 [aiohttp]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   -------------------------------------- - 22/23 [datasets]\n",
      "   ---------------------------------------- 23/23 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 attrs-25.3.0 certifi-2025.6.15 charset_normalizer-3.4.2 datasets-3.6.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.7.0 fsspec-2025.3.0 huggingface-hub-0.33.0 idna-3.10 multidict-6.4.4 multiprocess-0.70.16 propcache-0.3.2 pyarrow-20.0.0 pyyaml-6.0.2 requests-2.32.4 tqdm-4.67.1 urllib3-2.4.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cbdac6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\envs\\python_course\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Data Cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b6a2e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785741 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title_short  \\\n",
       "0       Senior Data Engineer   \n",
       "1               Data Analyst   \n",
       "2              Data Engineer   \n",
       "3              Data Engineer   \n",
       "4              Data Engineer   \n",
       "...                      ...   \n",
       "785736     Software Engineer   \n",
       "785737          Data Analyst   \n",
       "785738      Business Analyst   \n",
       "785739         Data Engineer   \n",
       "785740     Software Engineer   \n",
       "\n",
       "                                                job_title  \\\n",
       "0       Senior Clinical Data Engineer / Principal Clin...   \n",
       "1                                            Data Analyst   \n",
       "2       Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3       LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4                                  Data Engineer- Sr Jobs   \n",
       "...                                                   ...   \n",
       "785736                                    DevOps Engineer   \n",
       "785737                                   CRM Data Analyst   \n",
       "785738                     Commercial Analyst - Start Now   \n",
       "785739  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "0                             Watertown, CT            via Work Nearby   \n",
       "1              Guadalajara, Jalisco, Mexico           via BeBee México   \n",
       "2                           Berlin, Germany               via LinkedIn   \n",
       "3                           San Antonio, TX          via Diversity.com   \n",
       "4                            Washington, DC         via Clearance Jobs   \n",
       "...                                     ...                        ...   \n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "       job_schedule_type  job_work_from_home       search_location  \\\n",
       "0              Full-time               False  Texas, United States   \n",
       "1              Full-time               False                Mexico   \n",
       "2              Full-time               False               Germany   \n",
       "3              Full-time               False  Texas, United States   \n",
       "4              Full-time               False                 Sudan   \n",
       "...                  ...                 ...                   ...   \n",
       "785736   Pekerjaan tetap               False             Singapore   \n",
       "785737   Pekerjaan tetap               False               Germany   \n",
       "785738   Pekerjaan tetap               False              Malaysia   \n",
       "785739   Pekerjaan tetap               False                 Sudan   \n",
       "785740   Pekerjaan tetap               False                 India   \n",
       "\n",
       "           job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "0      2023-06-16 13:44:15                  False                 False   \n",
       "1      2023-01-14 13:18:07                  False                 False   \n",
       "2      2023-10-10 13:14:55                  False                 False   \n",
       "3      2023-07-04 13:01:41                   True                 False   \n",
       "4      2023-08-07 14:29:36                  False                 False   \n",
       "...                    ...                    ...                   ...   \n",
       "785736 2023-03-13 06:16:16                  False                 False   \n",
       "785737 2023-03-12 06:18:18                  False                 False   \n",
       "785738 2023-03-12 06:32:36                  False                 False   \n",
       "785739 2023-03-12 06:32:15                  False                 False   \n",
       "785740 2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "          job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0       United States        None              NaN              NaN   \n",
       "1              Mexico        None              NaN              NaN   \n",
       "2             Germany        None              NaN              NaN   \n",
       "3       United States        None              NaN              NaN   \n",
       "4               Sudan        None              NaN              NaN   \n",
       "...               ...         ...              ...              ...   \n",
       "785736      Singapore        None              NaN              NaN   \n",
       "785737        Germany        None              NaN              NaN   \n",
       "785738       Malaysia        None              NaN              NaN   \n",
       "785739          Sudan        None              NaN              NaN   \n",
       "785740          India        None              NaN              NaN   \n",
       "\n",
       "                              company_name  \\\n",
       "0                     Boehringer Ingelheim   \n",
       "1               Hewlett Packard Enterprise   \n",
       "2                 ALPHA Augmented Services   \n",
       "3             Southwest Research Institute   \n",
       "4                          Kristina Daniel   \n",
       "...                                    ...   \n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "0                                                    None   \n",
       "1       ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2       ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3       ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4       ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "...                                                   ...   \n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "0                                                    None  \n",
       "1       {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2       {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3       {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4       {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "...                                                   ...  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  \n",
       "\n",
       "[785741 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8ac1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9512fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785741 non-null  object        \n",
      " 1   job_title              785740 non-null  object        \n",
      " 2   job_location           784696 non-null  object        \n",
      " 3   job_via                785733 non-null  object        \n",
      " 4   job_schedule_type      773074 non-null  object        \n",
      " 5   job_work_from_home     785741 non-null  bool          \n",
      " 6   search_location        785741 non-null  object        \n",
      " 7   job_posted_date        785741 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785741 non-null  bool          \n",
      " 9   job_health_insurance   785741 non-null  bool          \n",
      " 10  job_country            785692 non-null  object        \n",
      " 11  salary_rate            33067 non-null   object        \n",
      " 12  salary_year_avg        22003 non-null   float64       \n",
      " 13  salary_hour_avg        10662 non-null   float64       \n",
      " 14  company_name           785723 non-null  object        \n",
      " 15  job_skills             668704 non-null  object        \n",
      " 16  job_type_skills        668704 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f0637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 785741\n",
      "Rows after: 0\n",
      "Rows dropped: 785741\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Count rows before dropping\n",
    "rows_before = len(df)\n",
    "\n",
    "\n",
    "\n",
    "# Count rows after dropping\n",
    "rows_after = len(df_cleaned)\n",
    "\n",
    "# Calculate how many records were dropped\n",
    "dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows before: {rows_before}\")\n",
    "print(f\"Rows after: {rows_after}\")\n",
    "print(f\"Rows dropped: {dropped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a3784bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salary_year_avg  salary_hour_avg\n",
       "0               NaN              NaN\n",
       "1               NaN              NaN\n",
       "2               NaN              NaN\n",
       "3               NaN              NaN\n",
       "4               NaN              NaN\n",
       "5               NaN              NaN\n",
       "6               NaN              NaN\n",
       "7               NaN              NaN\n",
       "8               NaN              NaN\n",
       "9               NaN              NaN\n",
       "10              NaN              NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display rows 0 to 10 and columns from 'salary_year_avg' to 'salary_hour_avg'\n",
    "df.loc[:10, 'salary_year_avg':'salary_hour_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb7d388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(45.97999954223633)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_year_avg'].median()\n",
    "df['salary_hour_avg'].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "956f0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_salary_year = df['salary_year_avg'].median()\n",
    "median_salary_hour = df['salary_hour_avg'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69a11518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(45.97999954223633)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_salary_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c2c5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a20a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_34928\\4253716410.py:1: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['salary_year_avg']=df['salary_year_avg'].fillna(median_salary_year)\n"
     ]
    }
   ],
   "source": [
    "df['salary_year_avg']=df['salary_year_avg'].fillna(median_salary_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d219e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         115000.0\n",
       "1         115000.0\n",
       "2         115000.0\n",
       "3         115000.0\n",
       "4         115000.0\n",
       "            ...   \n",
       "785736    115000.0\n",
       "785737    115000.0\n",
       "785738    115000.0\n",
       "785739    115000.0\n",
       "785740    115000.0\n",
       "Name: salary_year_avg, Length: 785741, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_year_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5c7c327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         45.98\n",
       "1         45.98\n",
       "2         45.98\n",
       "3         45.98\n",
       "4         45.98\n",
       "          ...  \n",
       "785736    45.98\n",
       "785737    45.98\n",
       "785738    45.98\n",
       "785739    45.98\n",
       "785740    45.98\n",
       "Name: salary_hour_avg, Length: 785741, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['salary_hour_avg']=df['salary_hour_avg'].fillna(median_salary_hour)\n",
    "df['salary_hour_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bf18e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_34928\\4029935520.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'salary_year_avg' and 'salary_hour_avg' with their median values\n",
    "for col in ['salary_year_avg', 'salary_hour_avg']:\n",
    "    median_val = df_filled[col].median()\n",
    "    df[col].fillna(median_val, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22573be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785741 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        salary_year_avg  salary_hour_avg\n",
       "0              115000.0            45.98\n",
       "1              115000.0            45.98\n",
       "2              115000.0            45.98\n",
       "3              115000.0            45.98\n",
       "4              115000.0            45.98\n",
       "...                 ...              ...\n",
       "785736         115000.0            45.98\n",
       "785737         115000.0            45.98\n",
       "785738         115000.0            45.98\n",
       "785739         115000.0            45.98\n",
       "785740         115000.0            45.98\n",
       "\n",
       "[785741 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled[['salary_year_avg', 'salary_hour_avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d7f0432",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a254def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_short</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_via</th>\n",
       "      <th>job_schedule_type</th>\n",
       "      <th>job_work_from_home</th>\n",
       "      <th>search_location</th>\n",
       "      <th>job_posted_date</th>\n",
       "      <th>job_no_degree_mention</th>\n",
       "      <th>job_health_insurance</th>\n",
       "      <th>job_country</th>\n",
       "      <th>salary_rate</th>\n",
       "      <th>salary_year_avg</th>\n",
       "      <th>salary_hour_avg</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_skills</th>\n",
       "      <th>job_type_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Senior Clinical Data Engineer / Principal Clin...</td>\n",
       "      <td>Watertown, CT</td>\n",
       "      <td>via Work Nearby</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-06-16 13:44:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>Boehringer Ingelheim</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Guadalajara, Jalisco, Mexico</td>\n",
       "      <td>via BeBee México</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>2023-01-14 13:18:07</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>['r', 'python', 'sql', 'nosql', 'power bi', 't...</td>\n",
       "      <td>{'analyst_tools': ['power bi', 'tableau'], 'pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer/Scientist/Analyst, Mid or Senior...</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-10-10 13:14:55</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>ALPHA Augmented Services</td>\n",
       "      <td>['python', 'sql', 'c#', 'azure', 'airflow', 'd...</td>\n",
       "      <td>{'analyst_tools': ['dax'], 'cloud': ['azure'],...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>via Diversity.com</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Texas, United States</td>\n",
       "      <td>2023-07-04 13:01:41</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>Southwest Research Institute</td>\n",
       "      <td>['python', 'c++', 'java', 'matlab', 'aws', 'te...</td>\n",
       "      <td>{'cloud': ['aws'], 'libraries': ['tensorflow',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Data Engineer- Sr Jobs</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>via Clearance Jobs</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-08-07 14:29:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>Kristina Daniel</td>\n",
       "      <td>['bash', 'python', 'oracle', 'aws', 'ansible',...</td>\n",
       "      <td>{'cloud': ['oracle', 'aws'], 'other': ['ansibl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785736</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Singapura</td>\n",
       "      <td>melalui Trabajo.org</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2023-03-13 06:16:16</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>CAREERSTAR INTERNATIONAL PTE. LTD.</td>\n",
       "      <td>['bash', 'python', 'perl', 'linux', 'unix', 'k...</td>\n",
       "      <td>{'os': ['linux', 'unix'], 'other': ['kubernete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785737</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>CRM Data Analyst</td>\n",
       "      <td>Bad Rodach, Jerman</td>\n",
       "      <td>melalui BeBee Deutschland</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2023-03-12 06:18:18</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Germany</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>HABA FAMILYGROUP</td>\n",
       "      <td>['sas', 'sas', 'sql', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['sas', 'excel'], 'programmi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785738</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Commercial Analyst - Start Now</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>melalui Ricebowl</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2023-03-12 06:32:36</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>Lendlease Corporation</td>\n",
       "      <td>['powerpoint', 'excel']</td>\n",
       "      <td>{'analyst_tools': ['powerpoint', 'excel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785739</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Principal Associate, Data Engineer (Remote-Eli...</td>\n",
       "      <td>Newark, New Jersey, Amerika Serikat</td>\n",
       "      <td>melalui Recruit.net</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>2023-03-12 06:32:15</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Sudan</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>Capital One</td>\n",
       "      <td>['python', 'go', 'nosql', 'sql', 'mongo', 'she...</td>\n",
       "      <td>{'cloud': ['aws', 'snowflake', 'azure', 'redsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785740</th>\n",
       "      <td>Software Engineer</td>\n",
       "      <td>AWS System Analyst</td>\n",
       "      <td>India</td>\n",
       "      <td>melalui Trigyn</td>\n",
       "      <td>Pekerjaan tetap</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>2023-03-13 06:16:31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>45.98</td>\n",
       "      <td>Trigyn</td>\n",
       "      <td>['aws', 'flow']</td>\n",
       "      <td>{'cloud': ['aws'], 'other': ['flow']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785640 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             job_title_short  \\\n",
       "0       Senior Data Engineer   \n",
       "1               Data Analyst   \n",
       "2              Data Engineer   \n",
       "3              Data Engineer   \n",
       "4              Data Engineer   \n",
       "...                      ...   \n",
       "785736     Software Engineer   \n",
       "785737          Data Analyst   \n",
       "785738      Business Analyst   \n",
       "785739         Data Engineer   \n",
       "785740     Software Engineer   \n",
       "\n",
       "                                                job_title  \\\n",
       "0       Senior Clinical Data Engineer / Principal Clin...   \n",
       "1                                            Data Analyst   \n",
       "2       Data Engineer/Scientist/Analyst, Mid or Senior...   \n",
       "3       LEAD ENGINEER - PRINCIPAL ANALYST - PRINCIPAL ...   \n",
       "4                                  Data Engineer- Sr Jobs   \n",
       "...                                                   ...   \n",
       "785736                                    DevOps Engineer   \n",
       "785737                                   CRM Data Analyst   \n",
       "785738                     Commercial Analyst - Start Now   \n",
       "785739  Principal Associate, Data Engineer (Remote-Eli...   \n",
       "785740                                 AWS System Analyst   \n",
       "\n",
       "                               job_location                    job_via  \\\n",
       "0                             Watertown, CT            via Work Nearby   \n",
       "1              Guadalajara, Jalisco, Mexico           via BeBee México   \n",
       "2                           Berlin, Germany               via LinkedIn   \n",
       "3                           San Antonio, TX          via Diversity.com   \n",
       "4                            Washington, DC         via Clearance Jobs   \n",
       "...                                     ...                        ...   \n",
       "785736                            Singapura        melalui Trabajo.org   \n",
       "785737                   Bad Rodach, Jerman  melalui BeBee Deutschland   \n",
       "785738                             Malaysia           melalui Ricebowl   \n",
       "785739  Newark, New Jersey, Amerika Serikat        melalui Recruit.net   \n",
       "785740                                India             melalui Trigyn   \n",
       "\n",
       "       job_schedule_type  job_work_from_home       search_location  \\\n",
       "0              Full-time               False  Texas, United States   \n",
       "1              Full-time               False                Mexico   \n",
       "2              Full-time               False               Germany   \n",
       "3              Full-time               False  Texas, United States   \n",
       "4              Full-time               False                 Sudan   \n",
       "...                  ...                 ...                   ...   \n",
       "785736   Pekerjaan tetap               False             Singapore   \n",
       "785737   Pekerjaan tetap               False               Germany   \n",
       "785738   Pekerjaan tetap               False              Malaysia   \n",
       "785739   Pekerjaan tetap               False                 Sudan   \n",
       "785740   Pekerjaan tetap               False                 India   \n",
       "\n",
       "           job_posted_date  job_no_degree_mention  job_health_insurance  \\\n",
       "0      2023-06-16 13:44:15                  False                 False   \n",
       "1      2023-01-14 13:18:07                  False                 False   \n",
       "2      2023-10-10 13:14:55                  False                 False   \n",
       "3      2023-07-04 13:01:41                   True                 False   \n",
       "4      2023-08-07 14:29:36                  False                 False   \n",
       "...                    ...                    ...                   ...   \n",
       "785736 2023-03-13 06:16:16                  False                 False   \n",
       "785737 2023-03-12 06:18:18                  False                 False   \n",
       "785738 2023-03-12 06:32:36                  False                 False   \n",
       "785739 2023-03-12 06:32:15                  False                 False   \n",
       "785740 2023-03-13 06:16:31                  False                 False   \n",
       "\n",
       "          job_country salary_rate  salary_year_avg  salary_hour_avg  \\\n",
       "0       United States        None         115000.0            45.98   \n",
       "1              Mexico        None         115000.0            45.98   \n",
       "2             Germany        None         115000.0            45.98   \n",
       "3       United States        None         115000.0            45.98   \n",
       "4               Sudan        None         115000.0            45.98   \n",
       "...               ...         ...              ...              ...   \n",
       "785736      Singapore        None         115000.0            45.98   \n",
       "785737        Germany        None         115000.0            45.98   \n",
       "785738       Malaysia        None         115000.0            45.98   \n",
       "785739          Sudan        None         115000.0            45.98   \n",
       "785740          India        None         115000.0            45.98   \n",
       "\n",
       "                              company_name  \\\n",
       "0                     Boehringer Ingelheim   \n",
       "1               Hewlett Packard Enterprise   \n",
       "2                 ALPHA Augmented Services   \n",
       "3             Southwest Research Institute   \n",
       "4                          Kristina Daniel   \n",
       "...                                    ...   \n",
       "785736  CAREERSTAR INTERNATIONAL PTE. LTD.   \n",
       "785737                    HABA FAMILYGROUP   \n",
       "785738               Lendlease Corporation   \n",
       "785739                         Capital One   \n",
       "785740                              Trigyn   \n",
       "\n",
       "                                               job_skills  \\\n",
       "0                                                    None   \n",
       "1       ['r', 'python', 'sql', 'nosql', 'power bi', 't...   \n",
       "2       ['python', 'sql', 'c#', 'azure', 'airflow', 'd...   \n",
       "3       ['python', 'c++', 'java', 'matlab', 'aws', 'te...   \n",
       "4       ['bash', 'python', 'oracle', 'aws', 'ansible',...   \n",
       "...                                                   ...   \n",
       "785736  ['bash', 'python', 'perl', 'linux', 'unix', 'k...   \n",
       "785737                     ['sas', 'sas', 'sql', 'excel']   \n",
       "785738                            ['powerpoint', 'excel']   \n",
       "785739  ['python', 'go', 'nosql', 'sql', 'mongo', 'she...   \n",
       "785740                                    ['aws', 'flow']   \n",
       "\n",
       "                                          job_type_skills  \n",
       "0                                                    None  \n",
       "1       {'analyst_tools': ['power bi', 'tableau'], 'pr...  \n",
       "2       {'analyst_tools': ['dax'], 'cloud': ['azure'],...  \n",
       "3       {'cloud': ['aws'], 'libraries': ['tensorflow',...  \n",
       "4       {'cloud': ['oracle', 'aws'], 'other': ['ansibl...  \n",
       "...                                                   ...  \n",
       "785736  {'os': ['linux', 'unix'], 'other': ['kubernete...  \n",
       "785737  {'analyst_tools': ['sas', 'excel'], 'programmi...  \n",
       "785738         {'analyst_tools': ['powerpoint', 'excel']}  \n",
       "785739  {'cloud': ['aws', 'snowflake', 'azure', 'redsh...  \n",
       "785740              {'cloud': ['aws'], 'other': ['flow']}  \n",
       "\n",
       "[785640 rows x 17 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5217a42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 785741\n",
      "Rows after: 785640\n",
      "Duplicates deleted: 101\n"
     ]
    }
   ],
   "source": [
    "# Count rows before removing duplicates\n",
    "rows_before = len(df)\n",
    "\n",
    "\n",
    "# Count rows after removing duplicates\n",
    "rows_after = len(df_unique.drop_duplicates())\n",
    "\n",
    "# Calculate how many duplicates were deleted\n",
    "duplicates_deleted = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows before: {rows_before}\")\n",
    "print(f\"Rows after: {rows_after}\")\n",
    "print(f\"Duplicates deleted: {duplicates_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d98ae9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 785741\n",
      "Rows after: 785640\n",
      "Duplicates deleted: 101\n"
     ]
    }
   ],
   "source": [
    "# Count rows before removing duplicates\n",
    "rows_before = len(df)\n",
    "\n",
    "# Remove duplicates\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "\n",
    "# Count rows after removing duplicates\n",
    "rows_after = len(df_no_duplicates)\n",
    "\n",
    "# Calculate how many duplicates were deleted\n",
    "duplicates_deleted = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows before: {rows_before}\")\n",
    "print(f\"Rows after: {rows_after}\")\n",
    "print(f\"Duplicates deleted: {duplicates_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15834f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique = df_unique.drop_duplicates(subset=['job_title', 'company_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7413f04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 785741\n",
      "Rows after: 508042\n",
      "Duplicates deleted: 277699\n"
     ]
    }
   ],
   "source": [
    "# Count rows before removing duplicates\n",
    "rows_before = len(df)\n",
    "\n",
    "\n",
    "# Count rows after removing duplicates\n",
    "rows_after = len(df_unique.drop_duplicates())\n",
    "\n",
    "# Calculate how many duplicates were deleted\n",
    "duplicates_deleted = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows before: {rows_before}\")\n",
    "print(f\"Rows after: {rows_after}\")\n",
    "print(f\"Duplicates deleted: {duplicates_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d42e999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 785741\n",
      "Rows after: 508042\n",
      "Duplicates: 277699\n"
     ]
    }
   ],
   "source": [
    "# Count rows before dropping duplicates\n",
    "rows_before = len(df)\n",
    "\n",
    "# Drop duplicates based on 'job_title' and 'company_name'\n",
    "df_no_duplicates = df.drop_duplicates(subset=['job_title', 'company_name'])\n",
    "\n",
    "# Count rows after dropping duplicates\n",
    "rows_after = len(df_no_duplicates)\n",
    "\n",
    "# Calculate how many duplicates were deleted\n",
    "duplicates_deleted = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows before: {rows_before}\")\n",
    "print(f\"Rows after: {rows_after}\")\n",
    "print(f\"Duplicates: {duplicates_deleted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039cac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
